{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from sklearn.utils import shuffle\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "resDir = r\"C:\\directory\\results\"\n",
    "trainin = pkl.load(open(resDir + \"\\\\trainin.pkl\", \"rb\")).T\n",
    "trainout = pkl.load(open(resDir + \"\\\\trainout.pkl\", \"rb\"))\n",
    "testin = pkl.load(open(resDir + \"\\\\testin.pkl\", \"rb\"))\n",
    "testout = pkl.load(open(resDir + \"\\\\testout.pkl\", \"rb\"))\n",
    "yscaler = pkl.load(open(resDir + \"\\\\yscaler.pkl\", \"rb\"))\n",
    "trainin = tf.convert_to_tensor(trainin)\n",
    "trainin = tf.transpose(trainin)\n",
    "trainout = tf.convert_to_tensor(trainout)\n",
    "testin = tf.convert_to_tensor(testin)\n",
    "testout = tf.convert_to_tensor(testout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37, 89700)\n"
     ]
    }
   ],
   "source": [
    "print(testin.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y_true,y_pred):\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    loss = tf.keras.losses.mean_absolute_error(y_true, y_pred)\n",
    "    return K.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_true,y_pred):\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    loss = tf.keras.losses.MSE(y_true, y_pred)\n",
    "    return K.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = tf.transpose(trainin).shape[0]\n",
    "output_size = tf.transpose(trainout).shape[0]\n",
    "\n",
    "lr = 10e-4\n",
    "epochs = 25\n",
    "batchsize = 1\n",
    "iterations = trainin.shape[0]//batchsize\n",
    "optimizer = tf.keras.optimizers.Adam(lr, beta_1=.9, beta_2=.999, epsilon=1e-7, decay=0.)\n",
    "loss_fn = mse\n",
    "\n",
    "metric =  keras.metrics.MeanSquaredError()\n",
    "val_metric = keras.metrics.MeanSquaredError()\n",
    "\n",
    "config = {'act1': 'relu', 'act2': 'linear', 'size1': 256, 'size2': 168, 'size3':28, 'size4': 7}\n",
    "\n",
    "inputs=keras.Input(shape = (input_size,), name = 'input')\n",
    "x = Dense(int(config['size1']), input_shape = (input_size,), activation = config['act1'])(inputs)\n",
    "x = Reshape(target_shape = (8, 8, 4))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(16, (3,3), activation = config['act1'], padding = \"same\")(x)\n",
    "x = Conv2D(16, (3,3), activation = config['act1'], padding = \"same\")(x)\n",
    "x = MaxPooling2D((2, 2), strides=2)(x)\n",
    "x = Conv2D(32, (3,3), activation = config['act1'], padding = \"same\")(x)\n",
    "x = Conv2D(32, (3,3), activation = config['act1'], padding = \"same\")(x)\n",
    "x = MaxPooling2D((2, 2), strides=2)(x)\n",
    "x = Conv2D(64, (3,3), activation = config['act1'], padding = \"same\")(x)\n",
    "x = Conv2D(64, (3,3), activation = config['act1'], padding = \"same\")(x)\n",
    "x = MaxPooling2D((2, 2), strides=2)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(int(config['size2']), activation = config['act1'])(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(int(config['size3']), activation = config['act1'])(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(int(config['size4']), activation = config['act1'])(x)\n",
    "x = BatchNormalization()(x)\n",
    "main_output = Dense(output_size, activation = config['act2'], name = 'main_output')(x)\n",
    "\n",
    "outputs = [main_output]\n",
    "\n",
    "model = keras.Model(inputs = inputs, outputs = outputs)\n",
    "modelname = (\"BnCNN_%.1e_%f_%f\" % (lr, epochs, batchsize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = tf.range(start=0, limit=tf.shape(trainin)[0], dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_on_batch():\n",
    "    start = epoch * batchsize\n",
    "    shuffled_indices = tf.random.shuffle(indices)\n",
    "    shuffledin = tf.gather(trainin, shuffled_indices)\n",
    "    shuffledout = tf.gather(trainout, shuffled_indices)\n",
    "    x_batch = shuffledin[start:start + batchsize, :]\n",
    "    y_batch = shuffledout[start:start + batchsize, :]\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        if iteration % 1 == 0:\n",
    "            current_loss = loss_fn(y_batch, model(x_batch))\n",
    "    \n",
    "    gradients = tape.gradient(current_loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients,model.trainable_variables))\n",
    "    \n",
    "    metric.update_state(y_batch, model(x_batch))\n",
    "    \n",
    "    \n",
    "    if iteration == (iterations - 1):\n",
    "        val_metric.update_state(testout, model(testin))\n",
    "        val_loss = loss_fn(testout, model(testin))\n",
    "        return current_loss, metric.result(), val_loss, val_metric.result()\n",
    "    else:\n",
    "        return current_loss, 0, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1/25 - Loss: 0.07575695961713791 - MSE: 0.8103616237640381 \\n\n",
      "Val_Loss: 0.8798912763595581 - Val_MSE: 0.8798912763595581\n",
      "\n",
      "Epoch: 2/25 - Loss: 0.027589742094278336 - MSE: 0.8812363147735596 \\n\n",
      "Val_Loss: 0.4642776846885681 - Val_MSE: 0.4642776846885681\n",
      "\n",
      "Epoch: 3/25 - Loss: 0.001142560737207532 - MSE: 0.4799664616584778 \\n\n",
      "Val_Loss: 0.6766042709350586 - Val_MSE: 0.6766042709350586\n",
      "\n",
      "Epoch: 4/25 - Loss: 0.009039019234478474 - MSE: 0.37387481331825256 \\n\n",
      "Val_Loss: 0.2728523313999176 - Val_MSE: 0.2728523313999176\n",
      "\n",
      "Epoch: 5/25 - Loss: 0.002281452063471079 - MSE: 0.08532393723726273 \\n\n",
      "Val_Loss: 0.13897894322872162 - Val_MSE: 0.13897894322872162\n",
      "\n",
      "Epoch: 6/25 - Loss: 0.020896898582577705 - MSE: 0.0941571295261383 \\n\n",
      "Val_Loss: 0.18501141667366028 - Val_MSE: 0.18501141667366028\n",
      "\n",
      "Epoch: 7/25 - Loss: 2.1374095013015904e-05 - MSE: 0.056820277124643326 \\n\n",
      "Val_Loss: 0.02593529224395752 - Val_MSE: 0.02593529224395752\n",
      "\n",
      "Epoch: 8/25 - Loss: 0.0006109442329034209 - MSE: 0.011239998042583466 \\n\n",
      "Val_Loss: 0.07533879578113556 - Val_MSE: 0.07533879578113556\n",
      "\n",
      "Epoch: 9/25 - Loss: 5.119742490933277e-05 - MSE: 0.049541838467121124 \\n\n",
      "Val_Loss: 0.12051283568143845 - Val_MSE: 0.12051283568143845\n",
      "\n",
      "Epoch: 10/25 - Loss: 0.00017861534433905035 - MSE: 0.06031071022152901 \\n\n",
      "Val_Loss: 0.04643253982067108 - Val_MSE: 0.04643253982067108\n",
      "\n",
      "Epoch: 11/25 - Loss: 0.0010985751869156957 - MSE: 0.00946068949997425 \\n\n",
      "Val_Loss: 0.02341022901237011 - Val_MSE: 0.02341022901237011\n",
      "\n",
      "Epoch: 12/25 - Loss: 3.5438952181721106e-05 - MSE: 0.00623288145288825 \\n\n",
      "Val_Loss: 0.032425086945295334 - Val_MSE: 0.032425086945295334\n",
      "\n",
      "Epoch: 13/25 - Loss: 0.0002224766358267516 - MSE: 0.0022347266785800457 \\n\n",
      "Val_Loss: 0.02563958242535591 - Val_MSE: 0.02563958242535591\n",
      "\n",
      "Epoch: 14/25 - Loss: 5.0808033847715706e-05 - MSE: 0.001035223831422627 \\n\n",
      "Val_Loss: 0.022745130583643913 - Val_MSE: 0.022745130583643913\n",
      "\n",
      "Epoch: 15/25 - Loss: 0.00017999509873334318 - MSE: 0.001579039846546948 \\n\n",
      "Val_Loss: 0.02232004702091217 - Val_MSE: 0.02232004702091217\n",
      "\n",
      "Epoch: 16/25 - Loss: 7.227627065731212e-05 - MSE: 0.0014912394108250737 \\n\n",
      "Val_Loss: 0.010817797854542732 - Val_MSE: 0.010817797854542732\n",
      "\n",
      "Epoch: 17/25 - Loss: 4.386633918329608e-06 - MSE: 0.00034916747245006263 \\n\n",
      "Val_Loss: 0.015809927135705948 - Val_MSE: 0.015809927135705948\n",
      "\n",
      "Epoch: 18/25 - Loss: 1.5710244042566046e-05 - MSE: 0.00010022579954238608 \\n\n",
      "Val_Loss: 0.01708676852285862 - Val_MSE: 0.01708676852285862\n",
      "\n",
      "Epoch: 19/25 - Loss: 0.0001973308390006423 - MSE: 0.00026931081083603203 \\n\n",
      "Val_Loss: 0.01553919818252325 - Val_MSE: 0.01553919818252325\n",
      "\n",
      "Epoch: 20/25 - Loss: 7.578144050057745e-06 - MSE: 0.0001302079763263464 \\n\n",
      "Val_Loss: 0.016843710094690323 - Val_MSE: 0.016843710094690323\n",
      "\n",
      "Epoch: 21/25 - Loss: 4.455331691133324e-06 - MSE: 0.00011499793617986143 \\n\n",
      "Val_Loss: 0.01318720355629921 - Val_MSE: 0.01318720355629921\n",
      "\n",
      "Epoch: 22/25 - Loss: 4.037836333736777e-05 - MSE: 4.7524019464617595e-05 \\n\n",
      "Val_Loss: 0.017110416665673256 - Val_MSE: 0.017110416665673256\n",
      "\n",
      "Epoch: 23/25 - Loss: 9.008432755308604e-08 - MSE: 2.3922244508867152e-05 \\n\n",
      "Val_Loss: 0.015558626502752304 - Val_MSE: 0.015558626502752304\n",
      "\n",
      "Epoch: 24/25 - Loss: 1.7287202354054898e-05 - MSE: 3.0489898563246243e-05 \\n\n",
      "Val_Loss: 0.016850903630256653 - Val_MSE: 0.016850903630256653\n",
      "\n",
      "Epoch: 25/25 - Loss: 1.2068305295542814e-05 - MSE: 3.364936856087297e-05 \\n\n",
      "Val_Loss: 0.018087727949023247 - Val_MSE: 0.018087727949023247\n"
     ]
    }
   ],
   "source": [
    "loss_history = []\n",
    "metric_history = []\n",
    "val_loss_history = []\n",
    "val_metric_history = []\n",
    "min_loss = 1\n",
    "for epoch in range(epochs):\n",
    "    for iteration in range(iterations):\n",
    "        current_loss, metric_result, val_loss, val_metric_result = train_model_on_batch()\n",
    "    if epoch % 1 == 0:\n",
    "        loss_history.append(current_loss.numpy())\n",
    "        metric_history.append(metric_result.numpy())\n",
    "        val_loss_history.append(val_loss.numpy())\n",
    "        val_metric_history.append(val_metric_result.numpy())\n",
    "        print(\"\\nEpoch: {}/{} - Loss: {} - MSE: {} \\\\n\\nVal_Loss: {} - Val_MSE: {}\".format(\n",
    "            (epoch + 1), epochs, loss_history[-1], metric_history[-1], val_loss_history[-1], val_metric_history[-1]))\n",
    "    if val_metric_result < .3:\n",
    "        if val_metric_result < min_loss:\n",
    "            model.save(\"%s\\\\%s.h5\" % (resDir,modelname))\n",
    "            min_loss = val_metric_result\n",
    "    metric.reset_states()\n",
    "    val_metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, '%s\\\\customlossmodel.png' % resDir, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 89700)]           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               22963456  \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 8, 8, 4)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 8, 8, 4)           16        \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 8, 8, 16)          592       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 8, 16)          2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 32)          4640      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 2, 2, 64)          18496     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 2, 2, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 168)               10920     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 168)               672       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 28)                4732      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 28)                112       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 203       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 7)                 28        \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 7)                 56        \n",
      "=================================================================\n",
      "Total params: 23,052,419\n",
      "Trainable params: 23,052,005\n",
      "Non-trainable params: 414\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "varnames = [\"A\", \"Tau\", \"S0\", \"Alpha\", \"Phi\", \"Beta\", \"Delta S\"]\n",
    "pred = tf.transpose(yscaler.inverse_transform(model(testin)))\n",
    "true = tf.transpose(yscaler.inverse_transform(testout))\n",
    "for i in range(pred.shape[0]):\n",
    "    plt.hist(pred[i], bins = 6, histtype='step', label = 'Model Pred')\n",
    "    plt.hist(true[i], bins = 6, histtype = 'step', label = 'Truth Label')\n",
    "    plt.title(varnames[i])\n",
    "    plt.legend()\n",
    "    plt.savefig(resDir + \"\\\\%s\" % varnames[i])\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.96337549e-03 -2.11606162e-05 -3.87439864e-05 -9.71652444e-06\n",
      "   3.50221435e-03 -3.44524520e-05 -6.79589684e-06 -1.24583381e-05\n",
      "  -1.49319309e-05 -3.09655803e-05 -2.76575225e-05 -2.27699416e-05\n",
      "  -3.82373470e-05 -1.65225043e-04 -2.23229068e-05 -1.43358844e-05\n",
      "  -1.42464774e-05  3.86771003e-03  3.82670204e-03 -1.73459190e-05\n",
      "  -1.45445007e-05 -1.57961982e-05 -3.20682662e-05 -1.63326400e-05\n",
      "  -2.10712093e-05 -2.69720691e-05 -4.23202651e-05 -3.23364871e-05\n",
      "  -2.67932552e-05 -9.53771050e-06  3.74158660e-03 -1.62134307e-05\n",
      "  -2.69720691e-05  3.54062954e-03 -1.49319309e-05 -2.05943721e-05\n",
      "  -1.08490127e-05]\n",
      " [-7.35951941e-02  4.91797924e-04  1.83457136e-03 -7.00443983e-04\n",
      "  -6.48343245e-02  1.43462420e-03 -8.07344913e-04 -3.72558832e-04\n",
      "  -1.40100718e-04  1.18672848e-03  1.03527308e-03  4.58478928e-04\n",
      "   1.68573856e-03  1.18941665e-02  3.76820564e-04 -1.14560127e-04\n",
      "  -1.32739544e-04 -7.18001406e-02 -7.09965507e-02  9.76920128e-05\n",
      "  -9.68873501e-05  3.23057175e-05  1.28370523e-03  2.65240669e-05\n",
      "   3.10719013e-04  8.47101212e-04  2.14087963e-03  1.23876333e-03\n",
      "   8.71360302e-04 -6.51299953e-04 -6.93908612e-02  2.68220901e-06\n",
      "   8.54372978e-04 -6.56573455e-02  3.73125076e-05  5.31673431e-04\n",
      "  -2.72244215e-04]\n",
      " [-4.42342591e-02  3.35463756e-04  1.91546368e-03 -1.13998962e-03\n",
      "  -3.91359162e-02  1.42849373e-03 -1.23929096e-03 -7.27287060e-04\n",
      "  -4.43568951e-04  1.14119934e-03  9.86227268e-04  2.60361904e-04\n",
      "   1.71543049e-03  1.38440220e-02  1.53431171e-04 -3.97315746e-04\n",
      "  -4.21157604e-04 -4.31748461e-02 -4.27086186e-02 -1.51744610e-04\n",
      "  -3.76096493e-04 -2.16236836e-04  1.25814366e-03 -2.33879810e-04\n",
      "   8.28592719e-05  7.33622784e-04  2.28393959e-03  1.18995594e-03\n",
      "   7.70816082e-04 -1.06774879e-03 -4.17675805e-02 -2.65231854e-04\n",
      "   7.43636364e-04 -3.95359826e-02 -1.94540745e-04  4.01505703e-04\n",
      "  -5.58009869e-04]\n",
      " [-1.58598079e-01  8.41040034e-04  4.23755111e-03 -2.28835283e-03\n",
      "  -1.39746441e-01  3.20019187e-03 -2.51727937e-03 -1.41691802e-03\n",
      "  -8.12973957e-04  2.58009495e-03  2.23331513e-03  7.00507183e-04\n",
      "   3.82200243e-03  2.98259741e-02  4.76885457e-04 -7.23015647e-04\n",
      "  -7.72785525e-04 -1.54690935e-01 -1.53004839e-01 -1.92698221e-04\n",
      "  -6.77567105e-04 -3.38461380e-04  2.82976391e-03 -3.70036941e-04\n",
      "   3.21019311e-04  1.70842173e-03  5.02482416e-03  2.69207718e-03\n",
      "   1.78344907e-03 -2.14147208e-03 -1.49542763e-01 -4.35616951e-04\n",
      "   1.72917904e-03 -1.41410603e-01 -3.01029663e-04  9.71857328e-04\n",
      "  -1.08277438e-03]\n",
      " [ 2.74474495e-02 -2.90814423e-04 -1.44940951e-03  7.77300812e-04\n",
      "   2.42391699e-02 -1.09535792e-03  8.55144478e-04  4.79873634e-04\n",
      "   2.73760773e-04 -8.83880638e-04 -7.65744232e-04 -2.42534660e-04\n",
      "  -1.30743124e-03 -1.01788674e-02 -1.66240715e-04  2.42885567e-04\n",
      "   2.59932495e-04  2.67789238e-02  2.65027159e-02  6.20450745e-05\n",
      "   2.27388359e-04  1.11636139e-04 -9.69115280e-04  1.22484184e-04\n",
      "  -1.13073372e-04 -5.86453461e-04 -1.71798804e-03 -9.22027611e-04\n",
      "  -6.12202667e-04  7.27113701e-04  2.59104841e-02  1.44895531e-04\n",
      "  -5.93606018e-04  2.45095366e-02  9.87615356e-05 -3.35517906e-04\n",
      "   3.65432716e-04]\n",
      " [-7.10855420e-02  6.31835302e-04  2.39944085e-03 -9.38791791e-04\n",
      "  -6.26123245e-02  1.87269970e-03 -1.07902662e-03 -5.06687919e-04\n",
      "  -2.00528661e-04  1.54646858e-03  1.34749337e-03  5.87370237e-04\n",
      "   2.20310315e-03  1.56429522e-02  4.79724248e-04 -1.66643421e-04\n",
      "  -1.90604488e-04 -6.93489010e-02 -6.85819681e-02  1.12708648e-04\n",
      "  -1.43382708e-04  2.68779597e-05  1.67418643e-03  1.90101466e-05\n",
      "   3.92865380e-04  1.09919532e-03  2.80278548e-03  1.61474570e-03\n",
      "   1.13132223e-03 -8.73822729e-04 -6.70284922e-02 -1.23716989e-05\n",
      "   1.10879167e-03 -6.34181793e-02  3.36579881e-05  6.84659918e-04\n",
      "  -3.73754660e-04]\n",
      " [ 1.23504739e-01 -1.15780424e-03 -4.50603556e-03  1.83971335e-03\n",
      "   1.09103541e-01 -3.50324701e-03  2.09720541e-03  1.01299692e-03\n",
      "   4.29825079e-04 -2.88657736e-03 -2.51679014e-03 -1.06255602e-03\n",
      "  -4.12647318e-03 -2.96204526e-02 -8.55251063e-04  3.60683691e-04\n",
      "   4.06817686e-04  1.20508652e-01  1.19291286e-01 -1.67175044e-04\n",
      "   3.16457044e-04 -8.38826986e-06 -3.12940668e-03  9.73154215e-06\n",
      "  -6.92888010e-04 -2.03697275e-03 -5.27255129e-03 -3.01210474e-03\n",
      "  -2.10039209e-03  1.71215941e-03  1.16629224e-01  7.02898612e-05\n",
      "  -2.05556940e-03  1.10344748e-01 -2.61504540e-05 -1.26366209e-03\n",
      "   7.45372068e-04]]\n"
     ]
    }
   ],
   "source": [
    "print(pred.numpy()-true.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.004003692930635151\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(pred.numpy()-true.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
